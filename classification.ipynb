{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Import and preparing of datasets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import time\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "# Check Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Define Hyper-parameters\n",
    "input_size = 784\n",
    "num_classes = 10\n",
    "num_epochs = 20\n",
    "batch_size = 100\n",
    "learning_rate = 0.01\n",
    "\n",
    "# MNIST dataset\n",
    "train_dataset = torchvision.datasets.MNIST(root='../../data',\n",
    "                                           train=True,\n",
    "                                           transform=transforms.ToTensor(),\n",
    "                                           download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='../../data',\n",
    "                                          train=False,\n",
    "                                          transform=transforms.ToTensor())\n",
    "\n",
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Network #1: 4-layer network\n",
    "a. Layer 1 – 20 neurons\n",
    "b. Layer 2 – 50 neurons\n",
    "c. Layer 3 – 20 neurons\n",
    "d. Layer 4 – output neuron with softmax activation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Step [100/600], Loss: 1.6554\n",
      "Epoch [1/20], Step [200/600], Loss: 1.7440\n",
      "Epoch [1/20], Step [300/600], Loss: 1.5787\n",
      "Epoch [1/20], Step [400/600], Loss: 1.6417\n",
      "Epoch [1/20], Step [500/600], Loss: 1.6933\n",
      "Epoch [1/20], Step [600/600], Loss: 1.6418\n",
      "Epoch [2/20], Step [100/600], Loss: 1.6432\n",
      "Epoch [2/20], Step [200/600], Loss: 1.6489\n",
      "Epoch [2/20], Step [300/600], Loss: 1.6435\n",
      "Epoch [2/20], Step [400/600], Loss: 1.6587\n",
      "Epoch [2/20], Step [500/600], Loss: 1.6516\n",
      "Epoch [2/20], Step [600/600], Loss: 1.6257\n",
      "Epoch [3/20], Step [100/600], Loss: 1.6396\n",
      "Epoch [3/20], Step [200/600], Loss: 1.6893\n",
      "Epoch [3/20], Step [300/600], Loss: 1.5933\n",
      "Epoch [3/20], Step [400/600], Loss: 1.6405\n",
      "Epoch [3/20], Step [500/600], Loss: 1.5708\n",
      "Epoch [3/20], Step [600/600], Loss: 1.7212\n",
      "Epoch [4/20], Step [100/600], Loss: 1.6263\n",
      "Epoch [4/20], Step [200/600], Loss: 1.7010\n",
      "Epoch [4/20], Step [300/600], Loss: 1.6308\n",
      "Epoch [4/20], Step [400/600], Loss: 1.6524\n",
      "Epoch [4/20], Step [500/600], Loss: 1.6412\n",
      "Epoch [4/20], Step [600/600], Loss: 1.6512\n",
      "Epoch [5/20], Step [100/600], Loss: 1.6938\n",
      "Epoch [5/20], Step [200/600], Loss: 1.6911\n",
      "Epoch [5/20], Step [300/600], Loss: 1.6412\n",
      "Epoch [5/20], Step [400/600], Loss: 1.6408\n",
      "Epoch [5/20], Step [500/600], Loss: 1.6203\n",
      "Epoch [5/20], Step [600/600], Loss: 1.6308\n",
      "Epoch [6/20], Step [100/600], Loss: 1.6208\n",
      "Epoch [6/20], Step [200/600], Loss: 1.5912\n",
      "Epoch [6/20], Step [300/600], Loss: 1.6246\n",
      "Epoch [6/20], Step [400/600], Loss: 1.6905\n",
      "Epoch [6/20], Step [500/600], Loss: 1.6931\n",
      "Epoch [6/20], Step [600/600], Loss: 1.7211\n",
      "Epoch [7/20], Step [100/600], Loss: 1.6711\n",
      "Epoch [7/20], Step [200/600], Loss: 1.6511\n",
      "Epoch [7/20], Step [300/600], Loss: 1.6110\n",
      "Epoch [7/20], Step [400/600], Loss: 1.6491\n",
      "Epoch [7/20], Step [500/600], Loss: 1.6613\n",
      "Epoch [7/20], Step [600/600], Loss: 1.6749\n",
      "Epoch [8/20], Step [100/600], Loss: 1.6112\n",
      "Epoch [8/20], Step [200/600], Loss: 1.6812\n",
      "Epoch [8/20], Step [300/600], Loss: 1.6212\n",
      "Epoch [8/20], Step [400/600], Loss: 1.6923\n",
      "Epoch [8/20], Step [500/600], Loss: 1.6212\n",
      "Epoch [8/20], Step [600/600], Loss: 1.5714\n",
      "Epoch [9/20], Step [100/600], Loss: 1.6806\n",
      "Epoch [9/20], Step [200/600], Loss: 1.6511\n",
      "Epoch [9/20], Step [300/600], Loss: 1.6112\n",
      "Epoch [9/20], Step [400/600], Loss: 1.7212\n",
      "Epoch [9/20], Step [500/600], Loss: 1.6680\n",
      "Epoch [9/20], Step [600/600], Loss: 1.7111\n",
      "Epoch [10/20], Step [100/600], Loss: 1.7212\n",
      "Epoch [10/20], Step [200/600], Loss: 1.7211\n",
      "Epoch [10/20], Step [300/600], Loss: 1.6412\n",
      "Epoch [10/20], Step [400/600], Loss: 1.6012\n",
      "Epoch [10/20], Step [500/600], Loss: 1.6712\n",
      "Epoch [10/20], Step [600/600], Loss: 1.6211\n",
      "Epoch [11/20], Step [100/600], Loss: 1.6412\n",
      "Epoch [11/20], Step [200/600], Loss: 1.6212\n",
      "Epoch [11/20], Step [300/600], Loss: 1.6312\n",
      "Epoch [11/20], Step [400/600], Loss: 1.6609\n",
      "Epoch [11/20], Step [500/600], Loss: 1.6012\n",
      "Epoch [11/20], Step [600/600], Loss: 1.6912\n",
      "Epoch [12/20], Step [100/600], Loss: 1.6312\n",
      "Epoch [12/20], Step [200/600], Loss: 1.6712\n",
      "Epoch [12/20], Step [300/600], Loss: 1.6912\n",
      "Epoch [12/20], Step [400/600], Loss: 1.7011\n",
      "Epoch [12/20], Step [500/600], Loss: 1.6512\n",
      "Epoch [12/20], Step [600/600], Loss: 1.6612\n",
      "Epoch [13/20], Step [100/600], Loss: 1.6412\n",
      "Epoch [13/20], Step [200/600], Loss: 1.6312\n",
      "Epoch [13/20], Step [300/600], Loss: 1.5712\n",
      "Epoch [13/20], Step [400/600], Loss: 1.7211\n",
      "Epoch [13/20], Step [500/600], Loss: 1.6212\n",
      "Epoch [13/20], Step [600/600], Loss: 1.6431\n",
      "Epoch [14/20], Step [100/600], Loss: 1.6112\n",
      "Epoch [14/20], Step [200/600], Loss: 1.6811\n",
      "Epoch [14/20], Step [300/600], Loss: 1.7312\n",
      "Epoch [14/20], Step [400/600], Loss: 1.6108\n",
      "Epoch [14/20], Step [500/600], Loss: 1.6612\n",
      "Epoch [14/20], Step [600/600], Loss: 1.6312\n",
      "Epoch [15/20], Step [100/600], Loss: 1.6511\n",
      "Epoch [15/20], Step [200/600], Loss: 1.7212\n",
      "Epoch [15/20], Step [300/600], Loss: 1.7812\n",
      "Epoch [15/20], Step [400/600], Loss: 1.6811\n",
      "Epoch [15/20], Step [500/600], Loss: 1.5912\n",
      "Epoch [15/20], Step [600/600], Loss: 1.6612\n",
      "Epoch [16/20], Step [100/600], Loss: 1.7011\n",
      "Epoch [16/20], Step [200/600], Loss: 1.6406\n",
      "Epoch [16/20], Step [300/600], Loss: 1.7312\n",
      "Epoch [16/20], Step [400/600], Loss: 1.5712\n",
      "Epoch [16/20], Step [500/600], Loss: 1.6312\n",
      "Epoch [16/20], Step [600/600], Loss: 1.7312\n",
      "Epoch [17/20], Step [100/600], Loss: 1.7512\n",
      "Epoch [17/20], Step [200/600], Loss: 1.6112\n",
      "Epoch [17/20], Step [300/600], Loss: 1.7112\n",
      "Epoch [17/20], Step [400/600], Loss: 1.6812\n",
      "Epoch [17/20], Step [500/600], Loss: 1.6512\n",
      "Epoch [17/20], Step [600/600], Loss: 1.6911\n",
      "Epoch [18/20], Step [100/600], Loss: 1.6512\n",
      "Epoch [18/20], Step [200/600], Loss: 1.7112\n",
      "Epoch [18/20], Step [300/600], Loss: 1.6812\n",
      "Epoch [18/20], Step [400/600], Loss: 1.6112\n",
      "Epoch [18/20], Step [500/600], Loss: 1.6912\n",
      "Epoch [18/20], Step [600/600], Loss: 1.6512\n",
      "Epoch [19/20], Step [100/600], Loss: 1.6012\n",
      "Epoch [19/20], Step [200/600], Loss: 1.6212\n",
      "Epoch [19/20], Step [300/600], Loss: 1.6812\n",
      "Epoch [19/20], Step [400/600], Loss: 1.7012\n",
      "Epoch [19/20], Step [500/600], Loss: 1.7512\n",
      "Epoch [19/20], Step [600/600], Loss: 1.7491\n",
      "Epoch [20/20], Step [100/600], Loss: 1.7112\n",
      "Epoch [20/20], Step [200/600], Loss: 1.6312\n",
      "Epoch [20/20], Step [300/600], Loss: 1.6012\n",
      "Epoch [20/20], Step [400/600], Loss: 1.7212\n",
      "Epoch [20/20], Step [500/600], Loss: 1.7078\n",
      "Epoch [20/20], Step [600/600], Loss: 1.6712\n",
      "Accuracy of the network on the 10000 test images: 77.68 % Total training time: 159.65 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8681    0.9673    0.9151       980\n",
      "           1     0.8814    0.9559    0.9172      1135\n",
      "           2     0.9828    0.5523    0.7072      1032\n",
      "           3     0.4805    0.9505    0.6383      1010\n",
      "           4     0.7523    0.9124    0.8247       982\n",
      "           5     0.0000    0.0000    0.0000       892\n",
      "           6     0.9326    0.8382    0.8829       958\n",
      "           7     0.9253    0.8794    0.9017      1028\n",
      "           8     0.7998    0.7136    0.7542       974\n",
      "           9     0.7552    0.8989    0.8208      1009\n",
      "\n",
      "    accuracy                         0.7768     10000\n",
      "   macro avg     0.7378    0.7669    0.7362     10000\n",
      "weighted avg     0.7475    0.7768    0.7458     10000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ivan\\anaconda3\\envs\\pytorch2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ivan\\anaconda3\\envs\\pytorch2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ivan\\anaconda3\\envs\\pytorch2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.fc1 = nn.Linear(input_size, 20)\n",
    "        self.fc2 = nn.Linear(20, 50)\n",
    "        self.fc3 = nn.Linear(50, 20)\n",
    "        self.fc4 = nn.Linear(20, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.fc1(x))\n",
    "        out = self.relu(self.fc2(out))\n",
    "        out = self.relu(self.fc3(out))\n",
    "        out = self.softmax(self.fc4(out))\n",
    "        return out\n",
    "\n",
    "model = NeuralNet(input_size, num_classes).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "start_time = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # Move tensors to the configured device\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backprpagation and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "\n",
    "\n",
    "# Test the model\n",
    "# In the test phase, don't need to compute gradients (for memory efficiency)\n",
    "y_true = list()\n",
    "y_pred = list()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        for i in range(len(outputs)):\n",
    "            y_true.append(labels[i].item())\n",
    "            y_pred.append(predicted[i].cpu())\n",
    "\n",
    "    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total),f\"Total training time: {total_time:.2f} seconds\")\n",
    "print(classification_report(y_true, y_pred,target_names=[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"], digits=4))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. Network #2: 6- layer network\n",
    "a. Layer 1 – 10 neurons\n",
    "b. Layer 2 – 20 neurons\n",
    "c. Layer 3 – 30 neurons\n",
    "d. Layer 4 – 20 neurons\n",
    "e. Layer 5 – 10 neurons\n",
    "f. Layer 6 – output neuron with softmax activation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Step [100/600], Loss: 1.9904\n",
      "Epoch [1/20], Step [200/600], Loss: 1.7853\n",
      "Epoch [1/20], Step [300/600], Loss: 1.8608\n",
      "Epoch [1/20], Step [400/600], Loss: 1.7279\n",
      "Epoch [1/20], Step [500/600], Loss: 1.7308\n",
      "Epoch [1/20], Step [600/600], Loss: 1.7964\n",
      "Epoch [2/20], Step [100/600], Loss: 1.6663\n",
      "Epoch [2/20], Step [200/600], Loss: 1.9329\n",
      "Epoch [2/20], Step [300/600], Loss: 1.7641\n",
      "Epoch [2/20], Step [400/600], Loss: 1.8159\n",
      "Epoch [2/20], Step [500/600], Loss: 1.6709\n",
      "Epoch [2/20], Step [600/600], Loss: 1.7202\n",
      "Epoch [3/20], Step [100/600], Loss: 1.7409\n",
      "Epoch [3/20], Step [200/600], Loss: 1.7414\n",
      "Epoch [3/20], Step [300/600], Loss: 1.6634\n",
      "Epoch [3/20], Step [400/600], Loss: 1.6701\n",
      "Epoch [3/20], Step [500/600], Loss: 1.6814\n",
      "Epoch [3/20], Step [600/600], Loss: 1.8298\n",
      "Epoch [4/20], Step [100/600], Loss: 1.7888\n",
      "Epoch [4/20], Step [200/600], Loss: 1.8806\n",
      "Epoch [4/20], Step [300/600], Loss: 1.8410\n",
      "Epoch [4/20], Step [400/600], Loss: 1.7211\n",
      "Epoch [4/20], Step [500/600], Loss: 1.7109\n",
      "Epoch [4/20], Step [600/600], Loss: 1.7308\n",
      "Epoch [5/20], Step [100/600], Loss: 1.6893\n",
      "Epoch [5/20], Step [200/600], Loss: 1.8009\n",
      "Epoch [5/20], Step [300/600], Loss: 1.7011\n",
      "Epoch [5/20], Step [400/600], Loss: 1.7812\n",
      "Epoch [5/20], Step [500/600], Loss: 1.8111\n",
      "Epoch [5/20], Step [600/600], Loss: 1.7811\n",
      "Epoch [6/20], Step [100/600], Loss: 1.8677\n",
      "Epoch [6/20], Step [200/600], Loss: 1.9105\n",
      "Epoch [6/20], Step [300/600], Loss: 1.8109\n",
      "Epoch [6/20], Step [400/600], Loss: 1.7611\n",
      "Epoch [6/20], Step [500/600], Loss: 1.7412\n",
      "Epoch [6/20], Step [600/600], Loss: 1.7112\n",
      "Epoch [7/20], Step [100/600], Loss: 1.7712\n",
      "Epoch [7/20], Step [200/600], Loss: 1.7808\n",
      "Epoch [7/20], Step [300/600], Loss: 1.8607\n",
      "Epoch [7/20], Step [400/600], Loss: 1.7512\n",
      "Epoch [7/20], Step [500/600], Loss: 1.7109\n",
      "Epoch [7/20], Step [600/600], Loss: 1.8008\n",
      "Epoch [8/20], Step [100/600], Loss: 1.8312\n",
      "Epoch [8/20], Step [200/600], Loss: 1.7811\n",
      "Epoch [8/20], Step [300/600], Loss: 1.7512\n",
      "Epoch [8/20], Step [400/600], Loss: 1.8203\n",
      "Epoch [8/20], Step [500/600], Loss: 1.7943\n",
      "Epoch [8/20], Step [600/600], Loss: 1.8111\n",
      "Epoch [9/20], Step [100/600], Loss: 1.8820\n",
      "Epoch [9/20], Step [200/600], Loss: 2.1111\n",
      "Epoch [9/20], Step [300/600], Loss: 1.9877\n",
      "Epoch [9/20], Step [400/600], Loss: 2.0311\n",
      "Epoch [9/20], Step [500/600], Loss: 1.8912\n",
      "Epoch [9/20], Step [600/600], Loss: 1.8812\n",
      "Epoch [10/20], Step [100/600], Loss: 1.9412\n",
      "Epoch [10/20], Step [200/600], Loss: 1.8209\n",
      "Epoch [10/20], Step [300/600], Loss: 1.7714\n",
      "Epoch [10/20], Step [400/600], Loss: 1.8708\n",
      "Epoch [10/20], Step [500/600], Loss: 1.8509\n",
      "Epoch [10/20], Step [600/600], Loss: 1.8312\n",
      "Epoch [11/20], Step [100/600], Loss: 1.9712\n",
      "Epoch [11/20], Step [200/600], Loss: 1.8212\n",
      "Epoch [11/20], Step [300/600], Loss: 1.9112\n",
      "Epoch [11/20], Step [400/600], Loss: 1.9012\n",
      "Epoch [11/20], Step [500/600], Loss: 1.9110\n",
      "Epoch [11/20], Step [600/600], Loss: 2.0011\n",
      "Epoch [12/20], Step [100/600], Loss: 1.8612\n",
      "Epoch [12/20], Step [200/600], Loss: 1.9011\n",
      "Epoch [12/20], Step [300/600], Loss: 1.9411\n",
      "Epoch [12/20], Step [400/600], Loss: 1.8812\n",
      "Epoch [12/20], Step [500/600], Loss: 1.9412\n",
      "Epoch [12/20], Step [600/600], Loss: 1.7512\n",
      "Epoch [13/20], Step [100/600], Loss: 1.8112\n",
      "Epoch [13/20], Step [200/600], Loss: 1.8311\n",
      "Epoch [13/20], Step [300/600], Loss: 1.7911\n",
      "Epoch [13/20], Step [400/600], Loss: 1.7912\n",
      "Epoch [13/20], Step [500/600], Loss: 1.7912\n",
      "Epoch [13/20], Step [600/600], Loss: 1.8912\n",
      "Epoch [14/20], Step [100/600], Loss: 2.0412\n",
      "Epoch [14/20], Step [200/600], Loss: 1.8512\n",
      "Epoch [14/20], Step [300/600], Loss: 1.8209\n",
      "Epoch [14/20], Step [400/600], Loss: 1.8712\n",
      "Epoch [14/20], Step [500/600], Loss: 1.8912\n",
      "Epoch [14/20], Step [600/600], Loss: 1.9912\n",
      "Epoch [15/20], Step [100/600], Loss: 1.9612\n",
      "Epoch [15/20], Step [200/600], Loss: 1.9212\n",
      "Epoch [15/20], Step [300/600], Loss: 1.9312\n",
      "Epoch [15/20], Step [400/600], Loss: 1.9312\n",
      "Epoch [15/20], Step [500/600], Loss: 1.8812\n",
      "Epoch [15/20], Step [600/600], Loss: 1.8912\n",
      "Epoch [16/20], Step [100/600], Loss: 1.9412\n",
      "Epoch [16/20], Step [200/600], Loss: 1.9312\n",
      "Epoch [16/20], Step [300/600], Loss: 1.8812\n",
      "Epoch [16/20], Step [400/600], Loss: 1.8912\n",
      "Epoch [16/20], Step [500/600], Loss: 1.8112\n",
      "Epoch [16/20], Step [600/600], Loss: 1.8412\n",
      "Epoch [17/20], Step [100/600], Loss: 1.8312\n",
      "Epoch [17/20], Step [200/600], Loss: 1.7312\n",
      "Epoch [17/20], Step [300/600], Loss: 1.9112\n",
      "Epoch [17/20], Step [400/600], Loss: 1.7812\n",
      "Epoch [17/20], Step [500/600], Loss: 1.8612\n",
      "Epoch [17/20], Step [600/600], Loss: 1.8512\n",
      "Epoch [18/20], Step [100/600], Loss: 1.9012\n",
      "Epoch [18/20], Step [200/600], Loss: 1.9512\n",
      "Epoch [18/20], Step [300/600], Loss: 1.9312\n",
      "Epoch [18/20], Step [400/600], Loss: 1.9512\n",
      "Epoch [18/20], Step [500/600], Loss: 1.7611\n",
      "Epoch [18/20], Step [600/600], Loss: 1.7812\n",
      "Epoch [19/20], Step [100/600], Loss: 1.8312\n",
      "Epoch [19/20], Step [200/600], Loss: 1.8812\n",
      "Epoch [19/20], Step [300/600], Loss: 1.9312\n",
      "Epoch [19/20], Step [400/600], Loss: 1.9112\n",
      "Epoch [19/20], Step [500/600], Loss: 2.0012\n",
      "Epoch [19/20], Step [600/600], Loss: 1.8312\n",
      "Epoch [20/20], Step [100/600], Loss: 1.9612\n",
      "Epoch [20/20], Step [200/600], Loss: 1.8212\n",
      "Epoch [20/20], Step [300/600], Loss: 1.9212\n",
      "Epoch [20/20], Step [400/600], Loss: 1.8612\n",
      "Epoch [20/20], Step [500/600], Loss: 1.8012\n",
      "Epoch [20/20], Step [600/600], Loss: 1.8612\n",
      "Accuracy of the network on the 10000 test images: 59.88 % Total training time: 170.02 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9248    0.8653    0.8940       980\n",
      "           1     0.8296    0.9824    0.8996      1135\n",
      "           2     0.0000    0.0000    0.0000      1032\n",
      "           3     0.5182    0.9426    0.6688      1010\n",
      "           4     0.0000    0.0000    0.0000       982\n",
      "           5     0.0000    0.0000    0.0000       892\n",
      "           6     0.6931    0.8017    0.7435       958\n",
      "           7     0.8291    0.6041    0.6989      1028\n",
      "           8     0.4159    0.8450    0.5574       974\n",
      "           9     0.4167    0.8533    0.5600      1009\n",
      "\n",
      "    accuracy                         0.5988     10000\n",
      "   macro avg     0.4627    0.5894    0.5022     10000\n",
      "weighted avg     0.4713    0.5988    0.5111     10000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ivan\\anaconda3\\envs\\pytorch2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ivan\\anaconda3\\envs\\pytorch2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ivan\\anaconda3\\envs\\pytorch2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.fc1 = nn.Linear(input_size, 10)\n",
    "        self.fc2 = nn.Linear(10, 20)\n",
    "        self.fc3 = nn.Linear(20, 30)\n",
    "        self.fc4 = nn.Linear(30, 20)\n",
    "        self.fc5 = nn.Linear(20, 10)\n",
    "        self.fc6 = nn.Linear(10, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.fc1(x))\n",
    "        out = self.relu(self.fc2(out))\n",
    "        out = self.relu(self.fc3(out))\n",
    "        out = self.relu(self.fc4(out))\n",
    "        out = self.relu(self.fc5(out))\n",
    "        out = self.softmax(self.fc6(out))\n",
    "        return out\n",
    "\n",
    "model = NeuralNet(input_size, num_classes).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "start_time = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # Move tensors to the configured device\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backprpagation and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "\n",
    "\n",
    "# Test the model\n",
    "# In the test phase, don't need to compute gradients (for memory efficiency)\n",
    "y_true = list()\n",
    "y_pred = list()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        for i in range(len(outputs)):\n",
    "            y_true.append(labels[i].item())\n",
    "            y_pred.append(predicted[i].cpu())\n",
    "\n",
    "    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total),f\"Total training time: {total_time:.2f} seconds\")\n",
    "print(classification_report(y_true, y_pred,target_names=[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"], digits=4))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "3. Network #3: 6- layer network\n",
    "a. Layer 1 – 10 neurons\n",
    "b. Layer 2 – 40 neurons\n",
    "c. Layer 3 – 70 neurons\n",
    "d. Layer 4 – 40 neurons\n",
    "e. Layer 5 – 10 neurons\n",
    "f. Layer 6 – output neuron with softmax activation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Step [100/600], Loss: 2.0286\n",
      "Epoch [1/20], Step [200/600], Loss: 1.9152\n",
      "Epoch [1/20], Step [300/600], Loss: 1.8038\n",
      "Epoch [1/20], Step [400/600], Loss: 1.8140\n",
      "Epoch [1/20], Step [500/600], Loss: 1.8415\n",
      "Epoch [1/20], Step [600/600], Loss: 1.8693\n",
      "Epoch [2/20], Step [100/600], Loss: 1.9243\n",
      "Epoch [2/20], Step [200/600], Loss: 1.8265\n",
      "Epoch [2/20], Step [300/600], Loss: 2.0530\n",
      "Epoch [2/20], Step [400/600], Loss: 2.0189\n",
      "Epoch [2/20], Step [500/600], Loss: 2.1111\n",
      "Epoch [2/20], Step [600/600], Loss: 2.2410\n",
      "Epoch [3/20], Step [100/600], Loss: 2.3711\n",
      "Epoch [3/20], Step [200/600], Loss: 2.3104\n",
      "Epoch [3/20], Step [300/600], Loss: 2.1800\n",
      "Epoch [3/20], Step [400/600], Loss: 2.1812\n",
      "Epoch [3/20], Step [500/600], Loss: 2.2607\n",
      "Epoch [3/20], Step [600/600], Loss: 2.1411\n",
      "Epoch [4/20], Step [100/600], Loss: 2.1412\n",
      "Epoch [4/20], Step [200/600], Loss: 2.2412\n",
      "Epoch [4/20], Step [300/600], Loss: 2.2312\n",
      "Epoch [4/20], Step [400/600], Loss: 2.2011\n",
      "Epoch [4/20], Step [500/600], Loss: 2.2912\n",
      "Epoch [4/20], Step [600/600], Loss: 2.3312\n",
      "Epoch [5/20], Step [100/600], Loss: 2.2311\n",
      "Epoch [5/20], Step [200/600], Loss: 2.2312\n",
      "Epoch [5/20], Step [300/600], Loss: 2.1412\n",
      "Epoch [5/20], Step [400/600], Loss: 2.1212\n",
      "Epoch [5/20], Step [500/600], Loss: 2.2112\n",
      "Epoch [5/20], Step [600/600], Loss: 2.1312\n",
      "Epoch [6/20], Step [100/600], Loss: 2.2812\n",
      "Epoch [6/20], Step [200/600], Loss: 2.2412\n",
      "Epoch [6/20], Step [300/600], Loss: 2.1812\n",
      "Epoch [6/20], Step [400/600], Loss: 2.2412\n",
      "Epoch [6/20], Step [500/600], Loss: 2.2012\n",
      "Epoch [6/20], Step [600/600], Loss: 2.2212\n",
      "Epoch [7/20], Step [100/600], Loss: 2.3312\n",
      "Epoch [7/20], Step [200/600], Loss: 2.2312\n",
      "Epoch [7/20], Step [300/600], Loss: 2.2812\n",
      "Epoch [7/20], Step [400/600], Loss: 2.2812\n",
      "Epoch [7/20], Step [500/600], Loss: 2.3012\n",
      "Epoch [7/20], Step [600/600], Loss: 2.3212\n",
      "Epoch [8/20], Step [100/600], Loss: 2.2912\n",
      "Epoch [8/20], Step [200/600], Loss: 2.2212\n",
      "Epoch [8/20], Step [300/600], Loss: 2.2612\n",
      "Epoch [8/20], Step [400/600], Loss: 2.1612\n",
      "Epoch [8/20], Step [500/600], Loss: 2.2007\n",
      "Epoch [8/20], Step [600/600], Loss: 2.3212\n",
      "Epoch [9/20], Step [100/600], Loss: 2.3012\n",
      "Epoch [9/20], Step [200/600], Loss: 2.3012\n",
      "Epoch [9/20], Step [300/600], Loss: 2.2712\n",
      "Epoch [9/20], Step [400/600], Loss: 2.3012\n",
      "Epoch [9/20], Step [500/600], Loss: 2.2712\n",
      "Epoch [9/20], Step [600/600], Loss: 2.2612\n",
      "Epoch [10/20], Step [100/600], Loss: 2.3212\n",
      "Epoch [10/20], Step [200/600], Loss: 2.2812\n",
      "Epoch [10/20], Step [300/600], Loss: 2.2712\n",
      "Epoch [10/20], Step [400/600], Loss: 2.3312\n",
      "Epoch [10/20], Step [500/600], Loss: 2.2505\n",
      "Epoch [10/20], Step [600/600], Loss: 2.2712\n",
      "Epoch [11/20], Step [100/600], Loss: 2.2912\n",
      "Epoch [11/20], Step [200/600], Loss: 2.2212\n",
      "Epoch [11/20], Step [300/600], Loss: 2.3212\n",
      "Epoch [11/20], Step [400/600], Loss: 2.2612\n",
      "Epoch [11/20], Step [500/600], Loss: 2.3212\n",
      "Epoch [11/20], Step [600/600], Loss: 2.3212\n",
      "Epoch [12/20], Step [100/600], Loss: 2.3712\n",
      "Epoch [12/20], Step [200/600], Loss: 2.2812\n",
      "Epoch [12/20], Step [300/600], Loss: 2.2912\n",
      "Epoch [12/20], Step [400/600], Loss: 2.3612\n",
      "Epoch [12/20], Step [500/600], Loss: 2.3612\n",
      "Epoch [12/20], Step [600/600], Loss: 2.3512\n",
      "Epoch [13/20], Step [100/600], Loss: 2.3212\n",
      "Epoch [13/20], Step [200/600], Loss: 2.3512\n",
      "Epoch [13/20], Step [300/600], Loss: 2.3712\n",
      "Epoch [13/20], Step [400/600], Loss: 2.4012\n",
      "Epoch [13/20], Step [500/600], Loss: 2.3712\n",
      "Epoch [13/20], Step [600/600], Loss: 2.2812\n",
      "Epoch [14/20], Step [100/600], Loss: 2.3612\n",
      "Epoch [14/20], Step [200/600], Loss: 2.4212\n",
      "Epoch [14/20], Step [300/600], Loss: 2.3512\n",
      "Epoch [14/20], Step [400/600], Loss: 2.3712\n",
      "Epoch [14/20], Step [500/600], Loss: 2.4012\n",
      "Epoch [14/20], Step [600/600], Loss: 2.3512\n",
      "Epoch [15/20], Step [100/600], Loss: 2.3512\n",
      "Epoch [15/20], Step [200/600], Loss: 2.4012\n",
      "Epoch [15/20], Step [300/600], Loss: 2.3512\n",
      "Epoch [15/20], Step [400/600], Loss: 2.3812\n",
      "Epoch [15/20], Step [500/600], Loss: 2.3412\n",
      "Epoch [15/20], Step [600/600], Loss: 2.3212\n",
      "Epoch [16/20], Step [100/600], Loss: 2.2912\n",
      "Epoch [16/20], Step [200/600], Loss: 2.3712\n",
      "Epoch [16/20], Step [300/600], Loss: 2.3512\n",
      "Epoch [16/20], Step [400/600], Loss: 2.3412\n",
      "Epoch [16/20], Step [500/600], Loss: 2.3512\n",
      "Epoch [16/20], Step [600/600], Loss: 2.3312\n",
      "Epoch [17/20], Step [100/600], Loss: 2.4012\n",
      "Epoch [17/20], Step [200/600], Loss: 2.3712\n",
      "Epoch [17/20], Step [300/600], Loss: 2.4112\n",
      "Epoch [17/20], Step [400/600], Loss: 2.3212\n",
      "Epoch [17/20], Step [500/600], Loss: 2.3312\n",
      "Epoch [17/20], Step [600/600], Loss: 2.3612\n",
      "Epoch [18/20], Step [100/600], Loss: 2.3312\n",
      "Epoch [18/20], Step [200/600], Loss: 2.2812\n",
      "Epoch [18/20], Step [300/600], Loss: 2.3312\n",
      "Epoch [18/20], Step [400/600], Loss: 2.4212\n",
      "Epoch [18/20], Step [500/600], Loss: 2.3912\n",
      "Epoch [18/20], Step [600/600], Loss: 2.3512\n",
      "Epoch [19/20], Step [100/600], Loss: 2.4012\n",
      "Epoch [19/20], Step [200/600], Loss: 2.3812\n",
      "Epoch [19/20], Step [300/600], Loss: 2.3312\n",
      "Epoch [19/20], Step [400/600], Loss: 2.4112\n",
      "Epoch [19/20], Step [500/600], Loss: 2.3512\n",
      "Epoch [19/20], Step [600/600], Loss: 2.3612\n",
      "Epoch [20/20], Step [100/600], Loss: 2.3512\n",
      "Epoch [20/20], Step [200/600], Loss: 2.3812\n",
      "Epoch [20/20], Step [300/600], Loss: 2.3712\n",
      "Epoch [20/20], Step [400/600], Loss: 2.3712\n",
      "Epoch [20/20], Step [500/600], Loss: 2.3712\n",
      "Epoch [20/20], Step [600/600], Loss: 2.3712\n",
      "Accuracy of the network on the 10000 test images: 10.1 % Total training time: 168.29 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       980\n",
      "           1     0.0000    0.0000    0.0000      1135\n",
      "           2     0.0000    0.0000    0.0000      1032\n",
      "           3     0.1012    1.0000    0.1837      1010\n",
      "           4     0.0000    0.0000    0.0000       982\n",
      "           5     0.0000    0.0000    0.0000       892\n",
      "           6     0.0000    0.0000    0.0000       958\n",
      "           7     0.0000    0.0000    0.0000      1028\n",
      "           8     0.0000    0.0000    0.0000       974\n",
      "           9     0.0000    0.0000    0.0000      1009\n",
      "\n",
      "    accuracy                         0.1010     10000\n",
      "   macro avg     0.0101    0.1000    0.0184     10000\n",
      "weighted avg     0.0102    0.1010    0.0186     10000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ivan\\anaconda3\\envs\\pytorch2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ivan\\anaconda3\\envs\\pytorch2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ivan\\anaconda3\\envs\\pytorch2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.fc1 = nn.Linear(input_size, 10)\n",
    "        self.fc2 = nn.Linear(10, 40)\n",
    "        self.fc3 = nn.Linear(40, 70)\n",
    "        self.fc4 = nn.Linear(70, 40)\n",
    "        self.fc5 = nn.Linear(40, 10)\n",
    "        self.fc6 = nn.Linear(10, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.fc1(x))\n",
    "        out = self.relu(self.fc2(out))\n",
    "        out = self.relu(self.fc3(out))\n",
    "        out = self.relu(self.fc4(out))\n",
    "        out = self.relu(self.fc5(out))\n",
    "        out = self.softmax(self.fc6(out))\n",
    "        return out\n",
    "\n",
    "model = NeuralNet(input_size, num_classes).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "start_time = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # Move tensors to the configured device\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backprpagation and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "\n",
    "\n",
    "# Test the model\n",
    "# In the test phase, don't need to compute gradients (for memory efficiency)\n",
    "y_true = list()\n",
    "y_pred = list()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        for i in range(len(outputs)):\n",
    "            y_true.append(labels[i].item())\n",
    "            y_pred.append(predicted[i].cpu())\n",
    "\n",
    "    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total),f\"Total training time: {total_time:.2f} seconds\")\n",
    "print(classification_report(y_true, y_pred,target_names=[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"], digits=4))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Which of the three models had the least amount of error for validation?\n",
    "The first model. It has the best acurracy with the test dataset: 77.68%. The others model have a very poor performance compated with the first one."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "How long it took to train each model?\n",
    "Model 1: 159.65 seconds\n",
    "Model 2: 170.02 seconds\n",
    "Model 3: 168.29 seconds\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
